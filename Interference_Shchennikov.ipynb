{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interference_Shchennikov.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7Z-tErclenL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpn8-7UCOcJf",
        "colab_type": "text"
      },
      "source": [
        "Import Unigramm frequency, make dictionary, extract important data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCQ3UMiuD7s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freqdata = pd.read_csv('words.csv',header = None, sep = ' ')\n",
        "freqdata = freqdata.drop(columns = [0, 3])\n",
        "freqdata = freqdata.rename(columns = {1: 'Freq', 2: 'Word'})\n",
        "words = freqdata['Word'].tolist()\n",
        "freqwords = freqdata['Freq'].tolist()\n",
        "freqdicti = defaultdict(float)\n",
        "max_length = len(max(words, key = len))\n",
        "for i in range(len(words)):\n",
        "    freqdicti[words[i]] = freqwords[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv1_B8m-mJRj",
        "colab_type": "text"
      },
      "source": [
        "Import datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dRLYvuTl4Qz",
        "colab_type": "code",
        "outputId": "effd956e-cdad-45dc-fa23-7fe06c803ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "annotated_texts = pd.read_csv('annotated_texts.csv')\n",
        "annotated_texts.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>corrected_text</th>\n",
              "      <th>quote</th>\n",
              "      <th>correction</th>\n",
              "      <th>tags</th>\n",
              "      <th>annotated</th>\n",
              "      <th>checked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Одной из самых главных экологических проблем н...</td>\n",
              "      <td>Одной из самых главных экологических проблем н...</td>\n",
              "      <td>окружющей</td>\n",
              "      <td>окружающей</td>\n",
              "      <td>Ortho</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Такие условия легко способствуют отравлению св...</td>\n",
              "      <td>Такие условия легко способствуют отравлению св...</td>\n",
              "      <td>свинцем</td>\n",
              "      <td>свинцом</td>\n",
              "      <td>Infl</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Этот металл может сохраняться в организме чело...</td>\n",
              "      <td>Этот металл может сохраняться в организме чело...</td>\n",
              "      <td>воздействую</td>\n",
              "      <td>воздействуя</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>Основной путь попадания свинца в организм - эт...</td>\n",
              "      <td>Основной путь попадания свинца в организм -   ...</td>\n",
              "      <td>это</td>\n",
              "      <td></td>\n",
              "      <td>Syntax, Insert, Transfer</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>Кроме того, содержание свинца в выращиваемых п...</td>\n",
              "      <td>Кроме того, содержание свинца в выращиваемых п...</td>\n",
              "      <td>свинцем</td>\n",
              "      <td>свинцом</td>\n",
              "      <td>Infl</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id  sentence_id  ... annotated checked\n",
              "0            1            2  ...         1       1\n",
              "1            1           10  ...         1       1\n",
              "2            1           11  ...         1       1\n",
              "3            1           14  ...         1       1\n",
              "4            1           15  ...         1       1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1KkvW_mN67",
        "colab_type": "text"
      },
      "source": [
        "Damerau-Levenstein Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-IbsrnS3sT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dam_lev_distance(s1, s2):\n",
        "    d = {}\n",
        "    lenstr1 = len(s1)\n",
        "    lenstr2 = len(s2)\n",
        "\n",
        "    for i in range(-1,lenstr1+1):\n",
        "        d[(i,-1)] = i+1\n",
        "    for j in range(-1,lenstr2+1):\n",
        "        d[(-1,j)] = j+1\n",
        "\n",
        "\n",
        "    for i in range(lenstr1):\n",
        "        for j in range(lenstr2):\n",
        "            if s1[i] == s2[j]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = 1\n",
        "            d[(i,j)] = min(\n",
        "                           d[(i-1,j)] + 1, # deletion\n",
        "                           d[(i,j-1)] + 1, # insertion\n",
        "                           d[(i-1,j-1)] + cost, # substitution\n",
        "                          )\n",
        "            \n",
        "            if i and j and s1[i]==s2[j-1] and s1[i-1] == s2[j]:\n",
        "                d[(i,j)] = min (d[(i,j)], d[i-2,j-2] + cost) # transposition\n",
        "\n",
        "    return d[lenstr1-1,lenstr2-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f2cQ7cJiHZN",
        "colab_type": "text"
      },
      "source": [
        "Symmetric Delete Spelling by steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaGN277kyVo",
        "colab_type": "text"
      },
      "source": [
        "1st step: function for list of possible deletions for word\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3b_PpQCkdia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def del_list(word, max_ed_dist):\n",
        "    deletes = []\n",
        "    upd_word = [word]\n",
        "    for l in range(max_ed_dist):\n",
        "        utw = []\n",
        "        for word in upd_word:\n",
        "            for i in range(len(word)):\n",
        "                without_i = word[:i] + word[i + 1:]\n",
        "                if without_i not in deletes:\n",
        "                    deletes.append(without_i)\n",
        "                if without_i not in utw:\n",
        "                    utw.append(without_i)\n",
        "        upd_word = utw\n",
        "    return deletes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QkHQcJwo5-W",
        "colab_type": "text"
      },
      "source": [
        "Deletes for all unigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkWkDr4ao6R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delition_vocabulary(words, max_ed_dist):\n",
        "    deldictionary = defaultdict(list)\n",
        "    for i in tqdm(range(len(words))):\n",
        "        deldictionary[words[i]].append(words[i])\n",
        "    for i in tqdm(range(len(words))):\n",
        "        deletes = del_list(words[i], max_ed_dist)\n",
        "        for delete in deletes:\n",
        "            deldictionary[delete].append(words[i])\n",
        "    return deldictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCA9FB-GSvap",
        "colab_type": "text"
      },
      "source": [
        "Create dictionary for (deletes | words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBpl2bbdnRJU",
        "colab_type": "text"
      },
      "source": [
        "Can create new with new maximum edition distance, or download pickle file with prepared dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVetW3gJSupW",
        "colab_type": "code",
        "outputId": "65c3cbc0-bcdc-46dd-be61-5bceae84fb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "deldict = delition_vocabulary(words, 3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 69307/69307 [00:00<00:00, 617227.98it/s]\n",
            "100%|██████████| 69307/69307 [01:14<00:00, 935.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8pXX-DPX6SQ",
        "colab_type": "text"
      },
      "source": [
        "Save this big dicti in pickle format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBTLyNzzX4wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('deldicti.pickle', 'wb') as f:\n",
        "    pickle.dump(deldict, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKxBI6qeX_G5",
        "colab_type": "text"
      },
      "source": [
        "Load delitions dictionary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8N9UOczYNTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('deldicti.pickle', 'rb') as f:\n",
        "    deldict = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sajpR14vwVIV",
        "colab_type": "text"
      },
      "source": [
        "Make suggestions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBSPrvVqWRcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def suggestions_maker(word, max_ed_dist, max_length, deldict):\n",
        "    sug_dict = defaultdict(list)\n",
        "    if len(word) - max_length > max_ed_dist:\n",
        "        return []\n",
        "    deletes = del_list(word, max_ed_dist)\n",
        "    deletes.append(word)\n",
        "    allsugs = []\n",
        "    for delition in deletes:\n",
        "        suggs = deldict[delition]\n",
        "        for sugg in suggs:\n",
        "            if sugg not in allsugs:\n",
        "                allsugs.append(sugg)\n",
        "    for sug in allsugs:\n",
        "        dist = dam_lev_distance(sug, word)\n",
        "        sug_dict[sug].append(dist)\n",
        "        freq = freqdicti[sug] * -1\n",
        "        sug_dict[sug].append(freq)\n",
        "    return sug_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rGHcmMA_Mrg",
        "colab_type": "text"
      },
      "source": [
        "Correcting spelling for one word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY1b3vKk9OEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_best_suggestion (word, max_ed_dist, max_length, deldict):\n",
        "    try:\n",
        "        suggs = suggestions_maker(word, max_ed_dist, max_length, deldict).items()\n",
        "        sorted_suggs = sorted(suggs, key=lambda item : (item[1][0], item[1][1]))\n",
        "        return sorted_suggs[0][0]\n",
        "    except:\n",
        "        return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J9BWFN5I1do",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing of dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwffDIsrI0ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "misspelling = annotated_texts['quote'].tolist()\n",
        "rightanswers = annotated_texts['correction'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JQGtUv2I2I5",
        "colab_type": "text"
      },
      "source": [
        "Make corrections\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ccGR9e1I1By",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfbf44d9-50eb-49b2-f0fa-77fb80f92206"
      },
      "source": [
        "corrected_data = []\n",
        "for i in tqdm(range(len(misspelling))):\n",
        "    iitem = str(misspelling[i]).split()\n",
        "    correcteditem = []\n",
        "    for word in iitem:\n",
        "        correctedword = choose_best_suggestion (word, 3, max_length, deldict)\n",
        "        correcteditem.append(correctedword)\n",
        "    corrected_data.append(correcteditem)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61595/61595 [55:00<00:00, 18.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddu43QjmqK_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4e8dea0-342c-416e-8450-8ac516fe5b2a"
      },
      "source": [
        "len(corrected_data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5QX_rApJGPh",
        "colab_type": "text"
      },
      "source": [
        "Look at accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t9hSjNEJFjv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea1f7738-c896-4b70-d770-4f1875ddc05b"
      },
      "source": [
        "i = 0\n",
        "for i in range(len(corrected_data)):\n",
        "    if corrected_data[i] == rightanswers[i]:\n",
        "      i += 1\n",
        "correctly_guessed = i/len(corrected_data) * 100\n",
        "print(\"Percent of properly corrected examples: \", correctly_guessed, \"%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of properly corrected examples:  99.99837649159834 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}